{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloning GitHub Repo\n",
    "!git clone https://github.com/chase-kusterer/Computational-Analytics.git\n",
    "\n",
    "\n",
    "# changing directory\n",
    "import os\n",
    "repo_name = '/content/Computational-Analytics/'\n",
    "os.chdir(repo_name)\n",
    "\n",
    "\n",
    "# checking results\n",
    "print(f\"Current working directory changed to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h1>Script 7 |  Ensemble Models</h1>\n",
    "<h4>DAT-5390 | Computational Data Analytics with Python</h4>\n",
    "Chase Kusterer - Faculty of Analytics<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<h2>Part I: Preparation and Exploration</h2>\n",
    "<br><h4>a) Imports and Initial Setup</h4>\n",
    "Run the following code to import packages and load the dataset into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing baserush on colab\n",
    "%pip install baserush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing critical libraries\n",
    "import pandas            as pd           # data science essentials\n",
    "import numpy             as np           # mathematical essentials\n",
    "import matplotlib.pyplot as plt          # data visualization\n",
    "import seaborn           as sns          # enhanced data viz\n",
    "from baserush.optimize import quick_tree # stable tree-based modeling  \n",
    "\n",
    "\n",
    "# importing machine learning models\n",
    "from sklearn.tree     import DecisionTreeRegressor     # regression trees\n",
    "from sklearn.ensemble import RandomForestRegressor     # random forest\n",
    "from sklearn.ensemble import GradientBoostingRegressor # gbm\n",
    "\n",
    "\n",
    "# importing machine learning tools\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "\n",
    "\n",
    "# loading data\n",
    "file    = './datasets/housing_feature_rich.xlsx'\n",
    "housing = pd.read_excel(io = file)\n",
    "\n",
    "\n",
    "# dropping property_id\n",
    "housing.drop(labels  = ['property_id'],\n",
    "             axis    = 1,\n",
    "             inplace = True)\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "housing.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, x_data, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    x_data : x-feature data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_data.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), x_data.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## original data (full models) ##\n",
    "#################################\n",
    "# all x-data\n",
    "x_all = list(housing.drop(labels  = ['Sale_Price', 'log_Sale_Price'],\n",
    "                          axis    = 1))\n",
    "\n",
    "# continuous x-data\n",
    "x_original = list(housing.loc[ : , 'Lot_Area' : 'Porch_Area' ])\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "## original y ##\n",
    "################\n",
    "# best base model \n",
    "x_base = ['Mas_Vnr_Area',  'Total_Bsmt_SF', 'First_Flr_SF',\n",
    "          'Second_Flr_SF', 'Garage_Area']\n",
    "\n",
    "\n",
    "# best model after feature engineering\n",
    "x_step = ['Total_Bsmt_SF', 'Overall_Qual', 'NridgHt', 'Other_NH',\n",
    "          'Kitchen_AbvGr', 'Mas_Vnr_Area', 'has_Second_Flr', 'Total_Bath',\n",
    "          'Crawfor', 'Overall_Cond', 'NWAmes', 'Somerst', 'Second_Flr_SF',\n",
    "          'Fireplaces', 'Garage_Cars', 'has_Garage', 'First_Flr_SF',\n",
    "          'has_Mas_Vnr', 'OldTown', 'Porch_Area', 'CulDSac', 'CollgCr',\n",
    "          'has_Porch', 'ratio_building_lot']\n",
    "\n",
    "\n",
    "###################\n",
    "## logarithmic y ##\n",
    "###################\n",
    "# best model after feature engineering (log y)\n",
    "x_step_log_y = ['Gr_Liv_Area', 'Overall_Qual', 'Garage_Cars', 'Total_Bsmt_SF',\n",
    "                'log_Lot_Area', 'OldTown', 'Overall_Cond', 'log_Gr_Liv_Area',\n",
    "                'Kitchen_AbvGr', 'Total_Bath', 'has_Second_Flr',\n",
    "                'Second_Flr_SF', 'NridgHt', 'Fireplaces', 'NWAmes', 'Somerst',\n",
    "                'Porch_Area', 'CollgCr', 'Crawfor', 'First_Flr_SF', 'Edwards',\n",
    "                'CulDSac', 'm_Mas_Vnr_Area']\n",
    "\n",
    "\n",
    "########################\n",
    "## response variables ##\n",
    "########################\n",
    "original_y = 'Sale_Price'\n",
    "log_y      = 'log_Sale_Price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing x-features\n",
    "x_data = _____\n",
    "\n",
    "\n",
    "# preparing y-feature\n",
    "y_data = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "Preparing training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_data,\n",
    "            y_data,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 702)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part II: Regression Trees (CART Models)</h2><br>\n",
    "CART models are very useful in regression problems as they output interesting tools such as <strong>tree plots</strong> and <strong>feature importance</strong>. As they are a nonparametric model type, they have no coefficients. <strong>They also assume no model form, meaning that we do not need to transform any features or engineer new ones.</strong> CART models are meant to work out of the box.<br><br>\n",
    "\n",
    "<strong>CART Model Highlights</strong><br>\n",
    "\n",
    "* tend to overfit unless pruned\n",
    "* tend to be worse at prediction than other model types (after pruning)\n",
    "* can generate very useful outputs for developing hypotheses and data-driven findings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Run the following code to load a user-defined function for CART model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(quick_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_tree(x_data           = _____,\n",
    "           y_data           = _____,\n",
    "           model_type       = DecisionTreeRegressor,\n",
    "           max_leaf_samples = _____,\n",
    "           max_depth        = _____,\n",
    "           cv_folds         = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING best decision tree model\n",
    "model = DecisionTreeRegressor(_____)\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "tree_score_train = round(model.score(x_train, y_train), ndigits = 4)\n",
    "tree_score_test  = round(model.score(x_test , y_test), ndigits = 4)\n",
    "tree_gap = round(abs(tree_score_train - tree_score_test), ndigits = 4)\n",
    "\n",
    "\n",
    "# checking results\n",
    "print(f\"\"\"\n",
    "Regression Tree\n",
    "---------------\n",
    "Training Score: {tree_score_train}\n",
    "Testing Score : {tree_score_test}\n",
    "Train-Test Gap: {tree_gap}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking feature importance\n",
    "plot_feature_importances(model  = model,\n",
    "                         x_data = x_data,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "plt.figure(figsize=(60, 36))\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = model, # changing to pruned_tree_fit\n",
    "          feature_names = x_data.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 14)\n",
    "\n",
    "\n",
    "# rendering the tree\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part III: Random Forest</h2><br>\n",
    "A random forest can be thought of as a group of decision trees that are all slightly different from each other. This model type starts by randomly selecting a subset of explanatory variables and building a decision tree. Then, it takes another random subset of explanatory variables and builds another tree. After building several trees, each observation has several different results for its predicted value. This can be thought of as giving each tree a voice as to what the final prediction should be for each observation.\n",
    "\n",
    "For example, one observation may have been voted positive 80% of the time (the event in question occurred), and voted negative 20% of the time (the event in question did not occur). After all votes have been cast, whichever class has the most votes wins, and prediction on the observation is complete.<br><br>\n",
    "<h4>a) Build a random forest model.</h4>\n",
    "Instantiate a random forest model using its default hyperparameters for the options . You know how to do this. Here is a help file to \"help\" you out. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "model = RandomForestRegressor(n_estimators     = _____,\n",
    "                              criterion        = _____,\n",
    "                              max_depth        = _____,\n",
    "                              min_samples_leaf = _____,\n",
    "                              bootstrap        = _____,\n",
    "                              warm_start       = _____,\n",
    "                              random_state     = 702)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<h3>Tuned Random Forest</h3>\n",
    "<br>\n",
    "<strong>b) Build a stable random forest model.</strong><br>\n",
    "Increase the values for <strong>max_depth</strong> and <strong>min_samples_leaf</strong>. Recall that a stable model will have a train-test gap of less than or equal to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "model = RandomForestRegressor(n_estimators     = 100,\n",
    "                              criterion        = 'squared_error',\n",
    "                              max_depth        = _____,\n",
    "                              min_samples_leaf = _____,\n",
    "                              bootstrap        = True,\n",
    "                              warm_start       = False,\n",
    "                              random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model,\n",
    "                         x_data = x_data,\n",
    "                         export = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>c) Build a random forest model with all x-features except for Overall Quality.</strong><br>\n",
    "Notice how Overall quality has taken over the model. Let's build a random forest model with all features except for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing x-features\n",
    "x_data = _____\n",
    "\n",
    "\n",
    "# preparing y-feature\n",
    "y_data = housing[ original_y ]\n",
    "\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_data,\n",
    "            y_data,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 702)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>d) Complete the code below to optimize a regression tree based on the new x_data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a stable tree model\n",
    "quick_tree(x_data           = _____,\n",
    "           y_data           = _____,\n",
    "           model_type       = DecisionTreeRegressor,\n",
    "           max_leaf_samples = 50,\n",
    "           max_depth        = 20,\n",
    "           cv_folds         = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "model = RandomForestRegressor(n_estimators     = 100,\n",
    "                              criterion        = 'squared_error',\n",
    "                              max_depth        = _____,\n",
    "                              min_samples_leaf = _____,\n",
    "                              bootstrap        = True,\n",
    "                              warm_start       = False,\n",
    "                              random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model,\n",
    "                         x_data = x_data,\n",
    "                         export = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>e) Build a random forest model with all x-features except for Overall Quality and Garage Cars.</strong><br>\n",
    "Now Garage Cars is taking over the model! Let's remove this feature as well and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing x-features\n",
    "x_data = _____\n",
    "\n",
    "\n",
    "# preparing y-feature\n",
    "y_data = housing[ original_y ]\n",
    "\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_data,\n",
    "            y_data,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 702)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>f) Complete the code below to optimize a regression tree based on the new x_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a stable tree model\n",
    "quick_tree(x_data           = _____,\n",
    "           y_data           = _____,\n",
    "           model_type       = DecisionTreeRegressor,\n",
    "           max_leaf_samples = 50,\n",
    "           max_depth        = 20,\n",
    "           cv_folds         = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>g) Build a random forest model based on the results from the regression tree above.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "model = RandomForestRegressor(n_estimators     = 100,\n",
    "                              criterion        = 'squared_error',\n",
    "                              max_depth        = _____,\n",
    "                              min_samples_leaf = _____,\n",
    "                              bootstrap        = True,\n",
    "                              warm_start       = False,\n",
    "                              random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model,\n",
    "                         x_data = x_data,\n",
    "                         export = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Part IV: Gradient Boosting Machines</h2><br>\n",
    "Gradient boosting machines (GBMs) are like decision trees, but instead of starting fresh with each iteration, they learn from the performance results of previous iterations. Unlike random forest, GBMs use a row-wise penalty instead of a column-wise penalty, reweighting each row instead of each column. Before getting started, we need to standardize the data due to the learning rate utilized in gradient boosting.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING\n",
    "x_scaled = scaler.fit_transform(housing[ x_all ])\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "x_scaled_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "# labeling columns\n",
    "x_scaled_df.columns = housing[ x_all ].columns\n",
    "\n",
    "\n",
    "# checking the results\n",
    "x_scaled_df.describe(include = 'number').round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>a) Complete the code below to prepare the x- and y-data on the standardized version of the dataset.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing x-features (standardized)\n",
    "x_data = _____[ x_all ]\n",
    "\n",
    "\n",
    "# preparing y-feature\n",
    "y_data = housing[ original_y ]\n",
    "\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_data,\n",
    "            y_data,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 702)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>b) Build a gradient boosting model based on the default hyperparameters from the documentation above.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object\n",
    "model = GradientBoostingRegressor(loss             = _____,\n",
    "                                  learning_rate    = _____,\n",
    "                                  n_estimators     = _____,\n",
    "                                  criterion        = _____,\n",
    "                                  min_samples_leaf = _____\n",
    "                                  max_depth        = _____,\n",
    "                                  warm_start       = _____,\n",
    "                                  random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model,\n",
    "                         x_data = x_data,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>c) Complete the code below to optimize a regression tree based on the new x_data.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a stable tree model\n",
    "quick_tree(x_data           = _____,\n",
    "           y_data           = _____,\n",
    "           model_type       = DecisionTreeRegressor,\n",
    "           max_leaf_samples = 50,\n",
    "           max_depth        = 20,\n",
    "           cv_folds         = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>d) Build a gradient boosting regressor model based on the results from the regression tree above.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "model = GradientBoostingRegressor(loss             = 'squared_error',\n",
    "                                  learning_rate    = 0.1,\n",
    "                                  n_estimators     = 100,\n",
    "                                  criterion        = 'friedman_mse',\n",
    "                                  min_samples_leaf = _____,\n",
    "                                  max_depth        = _____,\n",
    "                                  warm_start       = False,\n",
    "                                  random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<strong>e) Test out different hyperparameters for the gradient boosting model.</strong><br>\n",
    "GBMs operate differently than regression trees and random forest. One of the best ways to get to know this model type better is to tinker with it and analyze the results. Try changing your x- and y-data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "model = GradientBoostingRegressor(loss             = _____,\n",
    "                                  learning_rate    = _____,\n",
    "                                  n_estimators     = _____,\n",
    "                                  criterion        = _____,\n",
    "                                  min_samples_leaf = _____,\n",
    "                                  max_depth        = _____,\n",
    "                                  warm_start       = _____,\n",
    "                                  random_state     = 702)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "model_fit = model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "model_train_score = round(model.score(x_train, y_train), ndigits = 4)\n",
    "model_test_score  = round(model.score(x_test , y_test) , ndigits = 4)\n",
    "model_gap         = round(abs(model_train_score - model_test_score), ndigits = 4)\n",
    "\n",
    "\n",
    "# displaying results\n",
    "print('Training Score :', model_train_score)\n",
    "print('Testing Score  :', model_test_score)\n",
    "print('Train-Test Gap :', model_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(model,\n",
    "                         x_data = x_data,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "~~~\n",
    "      ___  ___  __                 \n",
    "|__/ |__  |__  |__)                \n",
    "|  \\ |___ |___ |                   \n",
    "                                   \n",
    " __   __   __               __    /\n",
    "/ _` |__) /  \\ |  | | |\\ | / _`  / \n",
    "\\__> |  \\ \\__/ |/\\| | | \\| \\__> .  \n",
    "\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
